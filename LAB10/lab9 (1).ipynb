{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from random import seed,sample,randrange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = [0, 0, 0]\n",
    "m2 = [0, 1, 0]\n",
    "m3 = [-1, 0, 1]\n",
    "m4 = [0, 0.5, 1]\n",
    "cov1 = [[1, 0, 0],[0, 1, 0],[0, 0, 1]]\n",
    "cov2 = [[1, 0, 1],[0, 2, 2],[1, 2, 5]]\n",
    "cov3 = [[2, 0, 0],[0, 6, 0],[0, 0, 1]]\n",
    "cov4 = [[2, 0, 0],[0, 1, 0],[0, 0, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=pd.DataFrame(np.random.multivariate_normal(m1, cov1, 1000),columns=list('ABC'))\n",
    "x1['y']=1\n",
    "x2=pd.DataFrame(np.random.multivariate_normal(m2, cov2, 1000),columns=list('ABC'))\n",
    "x2['y']=2\n",
    "x3=pd.DataFrame(np.random.multivariate_normal(m3, cov3, 1000),columns=list('ABC'))\n",
    "x3['y']=3\n",
    "x4=pd.DataFrame(np.random.multivariate_normal(m4, cov4, 1000),columns=list('ABC'))\n",
    "x4['y']=4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=x1\n",
    "data=data.append(x2,ignore_index=True)\n",
    "data=data.append(x3,ignore_index=True)\n",
    "data=data.append(x4,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop('y',axis=1)\n",
    "y=data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, input_dim=3, activation=\"relu\"))\n",
    "model.add(Dense(3, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 25        \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2680 samples, validate on 1320 samples\n",
      "Epoch 1/150\n",
      "2680/2680 [==============================] - 1s 324us/step - loss: 1.5929 - accuracy: 0.2955 - val_loss: 1.5631 - val_accuracy: 0.3462\n",
      "Epoch 2/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.5397 - accuracy: 0.3563 - val_loss: 1.4998 - val_accuracy: 0.3727\n",
      "Epoch 3/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.4587 - accuracy: 0.3806 - val_loss: 1.3961 - val_accuracy: 0.3765\n",
      "Epoch 4/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.3615 - accuracy: 0.3843 - val_loss: 1.3026 - val_accuracy: 0.3947\n",
      "Epoch 5/150\n",
      "2680/2680 [==============================] - 0s 24us/step - loss: 1.2912 - accuracy: 0.3978 - val_loss: 1.2527 - val_accuracy: 0.3886\n",
      "Epoch 6/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.2585 - accuracy: 0.3989 - val_loss: 1.2363 - val_accuracy: 0.3924\n",
      "Epoch 7/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.2358 - accuracy: 0.3929 - val_loss: 1.2153 - val_accuracy: 0.4356\n",
      "Epoch 8/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.2237 - accuracy: 0.4269 - val_loss: 1.2022 - val_accuracy: 0.4333\n",
      "Epoch 9/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.2115 - accuracy: 0.4224 - val_loss: 1.1965 - val_accuracy: 0.4348\n",
      "Epoch 10/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.2024 - accuracy: 0.4302 - val_loss: 1.1865 - val_accuracy: 0.4265\n",
      "Epoch 11/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.1996 - accuracy: 0.4261 - val_loss: 1.1809 - val_accuracy: 0.4258\n",
      "Epoch 12/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.1918 - accuracy: 0.4351 - val_loss: 1.1796 - val_accuracy: 0.4424\n",
      "Epoch 13/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.1862 - accuracy: 0.4295 - val_loss: 1.1735 - val_accuracy: 0.4348\n",
      "Epoch 14/150\n",
      "2680/2680 [==============================] - 0s 28us/step - loss: 1.1824 - accuracy: 0.4377 - val_loss: 1.1708 - val_accuracy: 0.4394\n",
      "Epoch 15/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1792 - accuracy: 0.4369 - val_loss: 1.1703 - val_accuracy: 0.4432\n",
      "Epoch 16/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.1766 - accuracy: 0.4373 - val_loss: 1.1661 - val_accuracy: 0.4455\n",
      "Epoch 17/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1739 - accuracy: 0.4366 - val_loss: 1.1674 - val_accuracy: 0.4470\n",
      "Epoch 18/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1707 - accuracy: 0.4418 - val_loss: 1.1596 - val_accuracy: 0.4424\n",
      "Epoch 19/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.1682 - accuracy: 0.4403 - val_loss: 1.1629 - val_accuracy: 0.4515\n",
      "Epoch 20/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.1658 - accuracy: 0.4470 - val_loss: 1.1570 - val_accuracy: 0.4462\n",
      "Epoch 21/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.1635 - accuracy: 0.4437 - val_loss: 1.1553 - val_accuracy: 0.4477\n",
      "Epoch 22/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1625 - accuracy: 0.4463 - val_loss: 1.1552 - val_accuracy: 0.4515\n",
      "Epoch 23/150\n",
      "2680/2680 [==============================] - 0s 27us/step - loss: 1.1657 - accuracy: 0.4444 - val_loss: 1.1459 - val_accuracy: 0.4583\n",
      "Epoch 24/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1625 - accuracy: 0.4563 - val_loss: 1.1560 - val_accuracy: 0.4455\n",
      "Epoch 25/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1610 - accuracy: 0.4466 - val_loss: 1.1446 - val_accuracy: 0.4621\n",
      "Epoch 26/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1583 - accuracy: 0.4571 - val_loss: 1.1454 - val_accuracy: 0.4614\n",
      "Epoch 27/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1550 - accuracy: 0.4582 - val_loss: 1.1388 - val_accuracy: 0.4712\n",
      "Epoch 28/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.1495 - accuracy: 0.4616 - val_loss: 1.1351 - val_accuracy: 0.4742\n",
      "Epoch 29/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1465 - accuracy: 0.4627 - val_loss: 1.1332 - val_accuracy: 0.4803\n",
      "Epoch 30/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1445 - accuracy: 0.4631 - val_loss: 1.1257 - val_accuracy: 0.4818\n",
      "Epoch 31/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.1456 - accuracy: 0.4638 - val_loss: 1.1306 - val_accuracy: 0.4894\n",
      "Epoch 32/150\n",
      "2680/2680 [==============================] - 0s 26us/step - loss: 1.1377 - accuracy: 0.4728 - val_loss: 1.1229 - val_accuracy: 0.4856\n",
      "Epoch 33/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1362 - accuracy: 0.4799 - val_loss: 1.1147 - val_accuracy: 0.4894\n",
      "Epoch 34/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.1336 - accuracy: 0.4780 - val_loss: 1.1220 - val_accuracy: 0.5061\n",
      "Epoch 35/150\n",
      "2680/2680 [==============================] - 0s 24us/step - loss: 1.1347 - accuracy: 0.4828 - val_loss: 1.1196 - val_accuracy: 0.5053\n",
      "Epoch 36/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1291 - accuracy: 0.4877 - val_loss: 1.1092 - val_accuracy: 0.5045\n",
      "Epoch 37/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1251 - accuracy: 0.4873 - val_loss: 1.1067 - val_accuracy: 0.5106\n",
      "Epoch 38/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1230 - accuracy: 0.4903 - val_loss: 1.1024 - val_accuracy: 0.5129\n",
      "Epoch 39/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1209 - accuracy: 0.4925 - val_loss: 1.1061 - val_accuracy: 0.5008\n",
      "Epoch 40/150\n",
      "2680/2680 [==============================] - 0s 23us/step - loss: 1.1186 - accuracy: 0.4974 - val_loss: 1.1022 - val_accuracy: 0.5045\n",
      "Epoch 41/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1189 - accuracy: 0.4881 - val_loss: 1.1100 - val_accuracy: 0.5061\n",
      "Epoch 42/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1227 - accuracy: 0.4993 - val_loss: 1.0984 - val_accuracy: 0.5159\n",
      "Epoch 43/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1155 - accuracy: 0.4925 - val_loss: 1.0920 - val_accuracy: 0.5227\n",
      "Epoch 44/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1203 - accuracy: 0.4925 - val_loss: 1.1239 - val_accuracy: 0.4955\n",
      "Epoch 45/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1185 - accuracy: 0.4970 - val_loss: 1.0940 - val_accuracy: 0.5129\n",
      "Epoch 46/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.1150 - accuracy: 0.4959 - val_loss: 1.0935 - val_accuracy: 0.5121\n",
      "Epoch 47/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.1139 - accuracy: 0.4944 - val_loss: 1.1010 - val_accuracy: 0.5152\n",
      "Epoch 48/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1123 - accuracy: 0.5011 - val_loss: 1.0915 - val_accuracy: 0.5159\n",
      "Epoch 49/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.1098 - accuracy: 0.4963 - val_loss: 1.0916 - val_accuracy: 0.5235\n",
      "Epoch 50/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1165 - accuracy: 0.4910 - val_loss: 1.0911 - val_accuracy: 0.5197\n",
      "Epoch 51/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1108 - accuracy: 0.4966 - val_loss: 1.1032 - val_accuracy: 0.5098\n",
      "Epoch 52/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1129 - accuracy: 0.5000 - val_loss: 1.0852 - val_accuracy: 0.5242\n",
      "Epoch 53/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1071 - accuracy: 0.4974 - val_loss: 1.0870 - val_accuracy: 0.5152\n",
      "Epoch 54/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1061 - accuracy: 0.4974 - val_loss: 1.0870 - val_accuracy: 0.5197\n",
      "Epoch 55/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1053 - accuracy: 0.4940 - val_loss: 1.0957 - val_accuracy: 0.5144\n",
      "Epoch 56/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1173 - accuracy: 0.4918 - val_loss: 1.0932 - val_accuracy: 0.5250\n",
      "Epoch 57/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.1131 - accuracy: 0.5011 - val_loss: 1.0870 - val_accuracy: 0.5159\n",
      "Epoch 58/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1059 - accuracy: 0.4989 - val_loss: 1.0831 - val_accuracy: 0.5182\n",
      "Epoch 59/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1038 - accuracy: 0.5015 - val_loss: 1.0846 - val_accuracy: 0.5205\n",
      "Epoch 60/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1096 - accuracy: 0.4892 - val_loss: 1.0931 - val_accuracy: 0.5197\n",
      "Epoch 61/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1074 - accuracy: 0.4974 - val_loss: 1.0798 - val_accuracy: 0.5235\n",
      "Epoch 62/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1037 - accuracy: 0.4959 - val_loss: 1.0969 - val_accuracy: 0.5114\n",
      "Epoch 63/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1015 - accuracy: 0.4966 - val_loss: 1.0834 - val_accuracy: 0.5152\n",
      "Epoch 64/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1038 - accuracy: 0.4955 - val_loss: 1.0817 - val_accuracy: 0.5189\n",
      "Epoch 65/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1035 - accuracy: 0.4940 - val_loss: 1.0859 - val_accuracy: 0.5182\n",
      "Epoch 66/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1043 - accuracy: 0.4978 - val_loss: 1.0794 - val_accuracy: 0.5220\n",
      "Epoch 67/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1016 - accuracy: 0.4948 - val_loss: 1.0919 - val_accuracy: 0.5129\n",
      "Epoch 68/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1064 - accuracy: 0.4925 - val_loss: 1.0806 - val_accuracy: 0.5220\n",
      "Epoch 69/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1051 - accuracy: 0.4959 - val_loss: 1.0834 - val_accuracy: 0.5220\n",
      "Epoch 70/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1062 - accuracy: 0.4981 - val_loss: 1.0984 - val_accuracy: 0.5098\n",
      "Epoch 71/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1141 - accuracy: 0.4933 - val_loss: 1.0874 - val_accuracy: 0.5159\n",
      "Epoch 72/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.0997 - accuracy: 0.4963 - val_loss: 1.0782 - val_accuracy: 0.5159\n",
      "Epoch 73/150\n",
      "2680/2680 [==============================] - ETA: 0s - loss: 1.1165 - accuracy: 0.50 - 0s 16us/step - loss: 1.1039 - accuracy: 0.4948 - val_loss: 1.0792 - val_accuracy: 0.5220\n",
      "Epoch 74/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1010 - accuracy: 0.4963 - val_loss: 1.0825 - val_accuracy: 0.5144\n",
      "Epoch 75/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.1040 - accuracy: 0.4858 - val_loss: 1.0760 - val_accuracy: 0.5189\n",
      "Epoch 76/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1023 - accuracy: 0.4989 - val_loss: 1.0808 - val_accuracy: 0.5174\n",
      "Epoch 77/150\n",
      "2680/2680 [==============================] - ETA: 0s - loss: 1.0878 - accuracy: 0.46 - 0s 19us/step - loss: 1.0992 - accuracy: 0.4985 - val_loss: 1.0801 - val_accuracy: 0.5159\n",
      "Epoch 78/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0999 - accuracy: 0.4981 - val_loss: 1.0771 - val_accuracy: 0.5182\n",
      "Epoch 79/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0966 - accuracy: 0.4940 - val_loss: 1.0822 - val_accuracy: 0.5136\n",
      "Epoch 80/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0981 - accuracy: 0.4996 - val_loss: 1.0769 - val_accuracy: 0.5167\n",
      "Epoch 81/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0992 - accuracy: 0.4974 - val_loss: 1.0769 - val_accuracy: 0.5212\n",
      "Epoch 82/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1002 - accuracy: 0.4981 - val_loss: 1.0762 - val_accuracy: 0.5182\n",
      "Epoch 83/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0985 - accuracy: 0.4937 - val_loss: 1.0788 - val_accuracy: 0.5159\n",
      "Epoch 84/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0971 - accuracy: 0.4963 - val_loss: 1.0818 - val_accuracy: 0.5121\n",
      "Epoch 85/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1002 - accuracy: 0.4944 - val_loss: 1.0786 - val_accuracy: 0.5144\n",
      "Epoch 86/150\n",
      "2680/2680 [==============================] - ETA: 0s - loss: 1.1319 - accuracy: 0.50 - 0s 20us/step - loss: 1.0968 - accuracy: 0.4937 - val_loss: 1.0774 - val_accuracy: 0.5205\n",
      "Epoch 87/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0956 - accuracy: 0.4970 - val_loss: 1.0768 - val_accuracy: 0.5167\n",
      "Epoch 88/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0954 - accuracy: 0.4974 - val_loss: 1.0800 - val_accuracy: 0.5197\n",
      "Epoch 89/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0973 - accuracy: 0.5011 - val_loss: 1.0783 - val_accuracy: 0.5152\n",
      "Epoch 90/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0969 - accuracy: 0.4940 - val_loss: 1.0817 - val_accuracy: 0.5114\n",
      "Epoch 91/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0976 - accuracy: 0.4963 - val_loss: 1.0782 - val_accuracy: 0.5136\n",
      "Epoch 92/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0947 - accuracy: 0.4963 - val_loss: 1.0708 - val_accuracy: 0.5250\n",
      "Epoch 93/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0975 - accuracy: 0.4955 - val_loss: 1.0745 - val_accuracy: 0.5144\n",
      "Epoch 94/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.1040 - accuracy: 0.4978 - val_loss: 1.0804 - val_accuracy: 0.5129\n",
      "Epoch 95/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0970 - accuracy: 0.4970 - val_loss: 1.0746 - val_accuracy: 0.5182\n",
      "Epoch 96/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0957 - accuracy: 0.4989 - val_loss: 1.0832 - val_accuracy: 0.5098\n",
      "Epoch 97/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0967 - accuracy: 0.4937 - val_loss: 1.0751 - val_accuracy: 0.5182\n",
      "Epoch 98/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0961 - accuracy: 0.4985 - val_loss: 1.0727 - val_accuracy: 0.5258\n",
      "Epoch 99/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.0943 - accuracy: 0.5000 - val_loss: 1.0808 - val_accuracy: 0.5136\n",
      "Epoch 100/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0985 - accuracy: 0.4933 - val_loss: 1.0725 - val_accuracy: 0.5205\n",
      "Epoch 101/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0957 - accuracy: 0.5004 - val_loss: 1.0844 - val_accuracy: 0.5136\n",
      "Epoch 102/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0960 - accuracy: 0.4959 - val_loss: 1.0773 - val_accuracy: 0.5152\n",
      "Epoch 103/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0998 - accuracy: 0.4907 - val_loss: 1.0764 - val_accuracy: 0.5167\n",
      "Epoch 104/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.0989 - accuracy: 0.4944 - val_loss: 1.0858 - val_accuracy: 0.5220\n",
      "Epoch 105/150\n",
      "2680/2680 [==============================] - 0s 24us/step - loss: 1.1003 - accuracy: 0.4951 - val_loss: 1.0811 - val_accuracy: 0.5144\n",
      "Epoch 106/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.1037 - accuracy: 0.4937 - val_loss: 1.0967 - val_accuracy: 0.5068\n",
      "Epoch 107/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.1036 - accuracy: 0.4940 - val_loss: 1.0808 - val_accuracy: 0.5159\n",
      "Epoch 108/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0992 - accuracy: 0.5007 - val_loss: 1.0737 - val_accuracy: 0.5121\n",
      "Epoch 109/150\n",
      "2680/2680 [==============================] - 0s 20us/step - loss: 1.0923 - accuracy: 0.4963 - val_loss: 1.0748 - val_accuracy: 0.5144\n",
      "Epoch 110/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.0953 - accuracy: 0.4948 - val_loss: 1.0786 - val_accuracy: 0.5129\n",
      "Epoch 111/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.0935 - accuracy: 0.4933 - val_loss: 1.0778 - val_accuracy: 0.5273\n",
      "Epoch 112/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0989 - accuracy: 0.5015 - val_loss: 1.0799 - val_accuracy: 0.5076\n",
      "Epoch 113/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0942 - accuracy: 0.4959 - val_loss: 1.0741 - val_accuracy: 0.5144\n",
      "Epoch 114/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0941 - accuracy: 0.4966 - val_loss: 1.0780 - val_accuracy: 0.5220\n",
      "Epoch 115/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0989 - accuracy: 0.4955 - val_loss: 1.0703 - val_accuracy: 0.5167\n",
      "Epoch 116/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0947 - accuracy: 0.4981 - val_loss: 1.0797 - val_accuracy: 0.5114\n",
      "Epoch 117/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0944 - accuracy: 0.4944 - val_loss: 1.0755 - val_accuracy: 0.5152\n",
      "Epoch 118/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.0921 - accuracy: 0.4892 - val_loss: 1.0778 - val_accuracy: 0.5159\n",
      "Epoch 119/150\n",
      "2680/2680 [==============================] - 0s 24us/step - loss: 1.0928 - accuracy: 0.4948 - val_loss: 1.0731 - val_accuracy: 0.5152\n",
      "Epoch 120/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0926 - accuracy: 0.4907 - val_loss: 1.0701 - val_accuracy: 0.5205\n",
      "Epoch 121/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0926 - accuracy: 0.4944 - val_loss: 1.0807 - val_accuracy: 0.5098\n",
      "Epoch 122/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0974 - accuracy: 0.4959 - val_loss: 1.0744 - val_accuracy: 0.5167\n",
      "Epoch 123/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0952 - accuracy: 0.4944 - val_loss: 1.0745 - val_accuracy: 0.5136\n",
      "Epoch 124/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0930 - accuracy: 0.4951 - val_loss: 1.0689 - val_accuracy: 0.5182\n",
      "Epoch 125/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0924 - accuracy: 0.4937 - val_loss: 1.0762 - val_accuracy: 0.5121\n",
      "Epoch 126/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0920 - accuracy: 0.4970 - val_loss: 1.0700 - val_accuracy: 0.5205\n",
      "Epoch 127/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0913 - accuracy: 0.4970 - val_loss: 1.0822 - val_accuracy: 0.5121\n",
      "Epoch 128/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.0912 - accuracy: 0.4970 - val_loss: 1.0741 - val_accuracy: 0.5159\n",
      "Epoch 129/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0913 - accuracy: 0.4989 - val_loss: 1.0752 - val_accuracy: 0.5129\n",
      "Epoch 130/150\n",
      "2680/2680 [==============================] - 0s 14us/step - loss: 1.0919 - accuracy: 0.5015 - val_loss: 1.0686 - val_accuracy: 0.5189\n",
      "Epoch 131/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0921 - accuracy: 0.4963 - val_loss: 1.0736 - val_accuracy: 0.5152\n",
      "Epoch 132/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.0917 - accuracy: 0.4989 - val_loss: 1.0726 - val_accuracy: 0.5114\n",
      "Epoch 133/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0905 - accuracy: 0.4993 - val_loss: 1.0771 - val_accuracy: 0.5182\n",
      "Epoch 134/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0957 - accuracy: 0.4963 - val_loss: 1.0763 - val_accuracy: 0.5121\n",
      "Epoch 135/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.0899 - accuracy: 0.5019 - val_loss: 1.0704 - val_accuracy: 0.5152\n",
      "Epoch 136/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0910 - accuracy: 0.4996 - val_loss: 1.0709 - val_accuracy: 0.5205\n",
      "Epoch 137/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.0905 - accuracy: 0.5011 - val_loss: 1.0769 - val_accuracy: 0.5136\n",
      "Epoch 138/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0906 - accuracy: 0.4985 - val_loss: 1.0794 - val_accuracy: 0.5174\n",
      "Epoch 139/150\n",
      "2680/2680 [==============================] - 0s 25us/step - loss: 1.0946 - accuracy: 0.4978 - val_loss: 1.0744 - val_accuracy: 0.5091\n",
      "Epoch 140/150\n",
      "2680/2680 [==============================] - 0s 21us/step - loss: 1.0935 - accuracy: 0.4963 - val_loss: 1.0773 - val_accuracy: 0.5121\n",
      "Epoch 141/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0913 - accuracy: 0.4944 - val_loss: 1.0776 - val_accuracy: 0.5129\n",
      "Epoch 142/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0913 - accuracy: 0.5004 - val_loss: 1.0728 - val_accuracy: 0.5106\n",
      "Epoch 143/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0898 - accuracy: 0.5030 - val_loss: 1.0726 - val_accuracy: 0.5167\n",
      "Epoch 144/150\n",
      "2680/2680 [==============================] - 0s 19us/step - loss: 1.0903 - accuracy: 0.4993 - val_loss: 1.0769 - val_accuracy: 0.5030\n",
      "Epoch 145/150\n",
      "2680/2680 [==============================] - 0s 15us/step - loss: 1.0891 - accuracy: 0.4989 - val_loss: 1.0798 - val_accuracy: 0.5136\n",
      "Epoch 146/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0904 - accuracy: 0.4989 - val_loss: 1.0775 - val_accuracy: 0.5205\n",
      "Epoch 147/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0901 - accuracy: 0.4974 - val_loss: 1.0739 - val_accuracy: 0.5114\n",
      "Epoch 148/150\n",
      "2680/2680 [==============================] - 0s 18us/step - loss: 1.0884 - accuracy: 0.4996 - val_loss: 1.0744 - val_accuracy: 0.5121\n",
      "Epoch 149/150\n",
      "2680/2680 [==============================] - 0s 16us/step - loss: 1.0892 - accuracy: 0.5015 - val_loss: 1.0764 - val_accuracy: 0.5136\n",
      "Epoch 150/150\n",
      "2680/2680 [==============================] - 0s 17us/step - loss: 1.0911 - accuracy: 0.4966 - val_loss: 1.0757 - val_accuracy: 0.5205\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=150, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "epoch_count = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1  2\n",
       "0  0.0  0.0  0\n",
       "1 -0.5 -0.5  0\n",
       "2 -1.0  0.0  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[0,0,0],[-0.5,-0.5,0],[-1,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict_classes(pd.DataFrame([[0,0,0],[-0.5,-0.5,0],[-1,0,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
