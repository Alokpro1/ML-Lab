{"cells":[{"source":["\n","Information about dataset, paysim1: \n","\n","URL of Kaggle Dataset page: https://www.kaggle.com/ntnu-testimon/paysim1"],"cell_type":"markdown","metadata":{"_uuid":"f9c307c75bae9a5b66f05d01c015937455400a6d"}},{"metadata":{"trusted":false,"_uuid":"5d7381e5a304f419c0ea2119d90e2d793f697766"},"cell_type":"code","source":["\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import matplotlib.cm as cm\n","from random import seed,sample\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, roc_curve, auc,\\\n","precision_score\n","from sklearn.ensemble import RandomForestClassifier\n"],"execution_count":2,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"71479e82537154fac60290ccb882f2ec1d7c778b"},"cell_type":"code","source":["\n","\n","data = pd.read_csv(\"credit_card.csv\")"],"execution_count":3,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"44dbc09b37da0a5abc23d3d15c1129ddde5ae5ea"},"cell_type":"code","source":["data.describe()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":"               step        amount  oldbalanceOrg  newbalanceOrig  \\\ncount  6.362620e+06  6.362620e+06   6.362620e+06    6.362620e+06   \nmean   2.433972e+02  1.798619e+05   8.338831e+05    8.551137e+05   \nstd    1.423320e+02  6.038582e+05   2.888243e+06    2.924049e+06   \nmin    1.000000e+00  0.000000e+00   0.000000e+00    0.000000e+00   \n25%    1.560000e+02  1.338957e+04   0.000000e+00    0.000000e+00   \n50%    2.390000e+02  7.487194e+04   1.420800e+04    0.000000e+00   \n75%    3.350000e+02  2.087215e+05   1.073152e+05    1.442584e+05   \nmax    7.430000e+02  9.244552e+07   5.958504e+07    4.958504e+07   \n\n       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \ncount    6.362620e+06    6.362620e+06  6.362620e+06    6.362620e+06  \nmean     1.100702e+06    1.224996e+06  1.290820e-03    2.514687e-06  \nstd      3.399180e+06    3.674129e+06  3.590480e-02    1.585775e-03  \nmin      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n25%      0.000000e+00    0.000000e+00  0.000000e+00    0.000000e+00  \n50%      1.327057e+05    2.146614e+05  0.000000e+00    0.000000e+00  \n75%      9.430367e+05    1.111909e+06  0.000000e+00    0.000000e+00  \nmax      3.560159e+08    3.561793e+08  1.000000e+00    1.000000e+00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>amount</th>\n      <th>oldbalanceOrg</th>\n      <th>newbalanceOrig</th>\n      <th>oldbalanceDest</th>\n      <th>newbalanceDest</th>\n      <th>isFraud</th>\n      <th>isFlaggedFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n      <td>6.362620e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.433972e+02</td>\n      <td>1.798619e+05</td>\n      <td>8.338831e+05</td>\n      <td>8.551137e+05</td>\n      <td>1.100702e+06</td>\n      <td>1.224996e+06</td>\n      <td>1.290820e-03</td>\n      <td>2.514687e-06</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1.423320e+02</td>\n      <td>6.038582e+05</td>\n      <td>2.888243e+06</td>\n      <td>2.924049e+06</td>\n      <td>3.399180e+06</td>\n      <td>3.674129e+06</td>\n      <td>3.590480e-02</td>\n      <td>1.585775e-03</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.560000e+02</td>\n      <td>1.338957e+04</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.390000e+02</td>\n      <td>7.487194e+04</td>\n      <td>1.420800e+04</td>\n      <td>0.000000e+00</td>\n      <td>1.327057e+05</td>\n      <td>2.146614e+05</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.350000e+02</td>\n      <td>2.087215e+05</td>\n      <td>1.073152e+05</td>\n      <td>1.442584e+05</td>\n      <td>9.430367e+05</td>\n      <td>1.111909e+06</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7.430000e+02</td>\n      <td>9.244552e+07</td>\n      <td>5.958504e+07</td>\n      <td>4.958504e+07</td>\n      <td>3.560159e+08</td>\n      <td>3.561793e+08</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":4}]},{"metadata":{"trusted":false,"_uuid":"eb9ae3a5fa40c19f93297aa82d405a1bd8350e63"},"cell_type":"code","source":["data.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":"(6362620, 11)"},"metadata":{},"execution_count":5}]},{"metadata":{"trusted":false,"_uuid":"a1956bb59911cfba3e6df5727f789ca05732c4c5"},"cell_type":"code","source":["data.head(7)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":"   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n5     1   PAYMENT   7817.71    C90045638        53860.0        46042.29   \n6     1   PAYMENT   7107.77   C154988899       183195.0       176087.23   \n\n      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n0  M1979787155             0.0             0.0        0               0  \n1  M2044282225             0.0             0.0        0               0  \n2   C553264065             0.0             0.0        1               0  \n3    C38997010         21182.0             0.0        1               0  \n4  M1230701703             0.0             0.0        0               0  \n5   M573487274             0.0             0.0        0               0  \n6   M408069119             0.0             0.0        0               0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>step</th>\n      <th>type</th>\n      <th>amount</th>\n      <th>nameOrig</th>\n      <th>oldbalanceOrg</th>\n      <th>newbalanceOrig</th>\n      <th>nameDest</th>\n      <th>oldbalanceDest</th>\n      <th>newbalanceDest</th>\n      <th>isFraud</th>\n      <th>isFlaggedFraud</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>9839.64</td>\n      <td>C1231006815</td>\n      <td>170136.0</td>\n      <td>160296.36</td>\n      <td>M1979787155</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>1864.28</td>\n      <td>C1666544295</td>\n      <td>21249.0</td>\n      <td>19384.72</td>\n      <td>M2044282225</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>TRANSFER</td>\n      <td>181.00</td>\n      <td>C1305486145</td>\n      <td>181.0</td>\n      <td>0.00</td>\n      <td>C553264065</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>CASH_OUT</td>\n      <td>181.00</td>\n      <td>C840083671</td>\n      <td>181.0</td>\n      <td>0.00</td>\n      <td>C38997010</td>\n      <td>21182.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>11668.14</td>\n      <td>C2048537720</td>\n      <td>41554.0</td>\n      <td>29885.86</td>\n      <td>M1230701703</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>7817.71</td>\n      <td>C90045638</td>\n      <td>53860.0</td>\n      <td>46042.29</td>\n      <td>M573487274</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>PAYMENT</td>\n      <td>7107.77</td>\n      <td>C154988899</td>\n      <td>183195.0</td>\n      <td>176087.23</td>\n      <td>M408069119</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":6}]},{"metadata":{"trusted":false,"_uuid":"6010843c4f59c40e7e4d11d7c3630625c0b57dea"},"cell_type":"code","source":["\n","data_new = data.copy() \n","data_new[\"type1\"] = np.nan \n","\n","\n","data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('C'),\"type1\"] = \"CC\" \n","data_new.loc[data.nameOrig.str.contains('C') & data.nameDest.str.contains('M'),\"type1\"] = \"CM\"\n","data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('C'),\"type1\"] = \"MC\"\n","data_new.loc[data.nameOrig.str.contains('M') & data.nameDest.str.contains('M'),\"type1\"] = \"MM\"\n","\n","    "],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0d12ec272d4c2cc42c0285d35e46d201238b34c"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"6e44c0b3b845746cb7c3376694a1938011dd2f5e"},"cell_type":"markdown","source":["### 1.4 Looking at Transaction Types\n","<a id='TransType'></a>"]},{"metadata":{"trusted":false,"_uuid":"967f70be1104b934e5d9ba05d6ee3bbbdd1c0985"},"cell_type":"code","source":["# seeing the counts of transactions by type\n","print(\"Fraud transactions by type: \\n\",fraud.type.value_counts())\n","print(\"\\n Valid transactions by type: \\n\",valid.type.value_counts())\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4622ec0cf0fd9c663ede0983210563ddea1e30ed"},"cell_type":"markdown","source":["#### Conclusion: \n","\n","From the dataset, it seems that fraud transactions only occur when the transaction type is CASH_OUT or TRANSFER.\n","\n","Since the dataset is sample of the population, I would've have resampled the data to see if this phenomenon held.\n","\n","Since I do not have access to the population, I will assume that transaction only occur when transaction type is either CASH_OUT or TRANSFER."]},{"metadata":{"trusted":false,"_uuid":"a45da65b70abfe8fb0f60a5bf76103bd20d9f415"},"cell_type":"code","source":["# Subsetting data according to the conclusion above\n","# I don't have to subset for the fraud dataset because all of their transaction types are either TRANSFER or CASH_OUT\n","\n","valid = valid[(valid[\"type\"] == \"CASH_OUT\")| (valid[\"type\"] == \"TRANSFER\")]\n","data_new = data_new[(data_new[\"type\"] == \"CASH_OUT\") | (data_new[\"type\"] == \"TRANSFER\")]"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eb37d471495eaa5a38501f30c572e0b8b8e24be7"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"afd8203ae6365bda92ba15e83dec1bc362658a43"},"cell_type":"markdown","source":["### 1.5 Looking balances before and after the transaction\n","<a id='bal'></a>"]},{"metadata":{"_uuid":"0636a698abb81fc3147be91075a194c3fab24157"},"cell_type":"markdown","source":["Most, if not all, of the observations have errors in calculating the balances before and after the transaction. "]},{"metadata":{"trusted":false,"_uuid":"e5e8fed35caa7a80b4d0ced95c99b6c3f5284246"},"cell_type":"code","source":["wrong_orig_bal = sum(data[\"oldbalanceOrg\"] - data[\"amount\"] != data[\"newbalanceOrig\"])\n","wrong_dest_bal = sum(data[\"newbalanceDest\"] + data[\"amount\"] != data[\"newbalanceDest\"])\n","print(\"Percentage of observations with balance errors in the account giving money: \", 100*round(wrong_orig_bal/len(data),2))\n","print(\"Percentage of observations with balance errors in the account receiving money: \", 100*round(wrong_dest_bal/len(data),2))"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f14bcf13fc5cff63929e1e652f5c81c1e7d5a8d9"},"cell_type":"markdown","source":["Almost all of the observations have inaccurately portrayed what happens to the account receiving money and the account sending money.\n","\n","Some form of complete or partial imputation (filling/replacing missing or wrong values) must happen."]},{"metadata":{"_uuid":"b3352c9b9487e1fd8358537f183a6288c38e6436"},"cell_type":"markdown","source":["Here are some hypothesis/assumptions that I will test soon:\n","\n","1. There are no negative values in this dataset.\n","2. The most a given can give is how much is in their account.\n","3. The most a receiver should have in their account is the amount given to them in the transaction."]},{"metadata":{"trusted":false,"_uuid":"811f651d59cc1c0b810cdf73b8588d7114eaa023"},"cell_type":"code","source":["## Calculating some quantities to justify or reject some assumptions\n","\n","# flatten the subsetted dataframe of floats into an array of floats\n","relevant_cols = data[[\"amount\",\"oldbalanceOrg\",\"newbalanceOrig\",\"oldbalanceDest\",\"newbalanceDest\"]].values.flatten()\n","# number of observations with negative numbers\n","num_neg_amt = sum(n < 0 for n in relevant_cols)\n","# number of observations where the amount given is greater than the amount that is in the giver's account\n","num_amt_oldgiver = sum(data[\"amount\"] > data[\"oldbalanceOrg\"]) \n","# number of observations where the amount received is greater than the amount that is in the receiver's account\n","num_amt_newreceiver = sum(data[\"amount\"] > data[\"newbalanceDest\"]) \n","\n","print(\"number of observations with negative numbers: \", num_neg_amt)\n","print(\"number of observations where the amount given is greater than the amount that is in the giver's account: \"\n","      , num_amt_oldgiver)\n","print(\"number of observations where the amount received is greater than the amount that is in the receiver's account: \"\n","      , num_amt_newreceiver)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a9b15118fba7c97382ad7714792a4d3a13b60d5"},"cell_type":"markdown","source":["With these calculations, hypotheses 2 and 3 have been rejected. "]},{"metadata":{"trusted":false,"_uuid":"2f5ebba9614f33b0b0ea91c964449a326bb5f432"},"cell_type":"code","source":["# counting number of observations where oldbalanceOrg - amount != newbalanceOrig or newbalanceDest + amount != newbalanceDest\n","# Essentially, I am counting the number of observations where the effects of the transactions are not properly reflected\n","# the balances of account sending money and the account receiving money.\n","\n","num_wrong_bal = (data[\"oldbalanceOrg\"] - data[\"amount\"] != data[\"newbalanceOrig\"]) | (data[\"newbalanceDest\"] + data[\"amount\"] != data[\"newbalanceDest\"])\n","print(\"Percentage of observations with balance errors: \", 100*round(sum(num_wrong_bal)/len(data),2))\n","\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a128c06e0f798bae1d813defd52ba952016801da"},"cell_type":"markdown","source":["In fact, **all** observations have balance contain errors.\n","\n","Since I don't know why these errors are caused, I cannot replace them. \n","\n","I also don't want to get rid of the variables oldbalanceOrg, newbalanceOrig, newbalanceDest, oldbalanceDest since they might be important in identifying fraudulent transactions from valid transactions.\n","\n","So for now, I will them be.\n","\n","However, do these errors differ between fraudulent and valid transactions?"]},{"metadata":{"trusted":false,"_uuid":"16cffdae719b47c107766e5c2da0291016cb099d"},"cell_type":"code","source":["# adding features errorBalanceOrg, errorBalanceDest\n","data_new[\"errorBalanceOrg\"] = data_new.newbalanceOrig + data_new.amount - data_new.oldbalanceOrg\n","data_new[\"errorBalanceDest\"] = data_new.oldbalanceDest + data_new.amount - data_new.newbalanceDest\n","\n","# Subsetting data into observations with fraud and valid transactions:\n","fraud = data_new[data_new[\"isFraud\"] == 1]\n","valid = data_new[data_new[\"isFraud\"] == 0]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"79504c6e113c06cd29aee380035a364e04e3a1ce"},"cell_type":"code","source":["print(\"Summary statistics of errorBalanceOrg for fraudulent transactions: \\n\",fraud[\"errorBalanceOrg\"].describe())\n","print(\"\\n Summary statistics of errorBalanceOrg for valid transactions: \\n\",valid[\"errorBalanceOrg\"].describe())"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"065e73093fbb0d2ba6acdfdc04acf0b03f1861b4"},"cell_type":"markdown","source":["From the summary statistics on the errorBalanceOrg, it seems that a large proportion of the data have an error of 0 or close to zero. This is indicated by the fact that the most negative error is -7.450581e-09 or $-7.450581 x 10^{-9}$ which is very small and close to 0, and the 3rd quartile is 0 (that is, about 75% of the data is between -7.450581e-09 and 0). However, there are some large errors, the largest error being 10,000,000.\n","\n","On the other hand, for valid transactions, a large proportion of the data have large errors. For instance,\n","about 75% of the data haver errors exceeding 52,613.43 (the first quartile). The largest error is 92,445,520."]},{"metadata":{"trusted":false,"_uuid":"a95194c55bff70e8cbacf98df1616c26d368874e"},"cell_type":"code","source":["print(\"Summary statistics of errorBalanceDest for fraudulent transactions: \\n\",fraud[\"errorBalanceDest\"].describe())\n","print(\"\\n Summary statistics of errorBalanceDest for valid transactions: \\n\",valid[\"errorBalanceDest\"].describe())"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f58e01f4709d37660ade135df048a6d5a78d2391"},"cell_type":"markdown","source":["From the summary statistics of the errorBalanceDest variable, the errors are huge in both directions (both fraudulent and valid transactions have large positive and negative errors in the accounts where money has been moved to.)\n","\n","Let's see what the differences look like when I plot errorBalanceOrg and errorBalanceDest together."]},{"metadata":{"trusted":false,"_uuid":"c6de711f5589f9a13b8ad6b6bb7bc49ed409315d"},"cell_type":"code","source":["errors = [\"errorBalanceOrg\", \"errorBalanceDest\"]\n","ax = plt.subplot()\n","\n","fplot = fraud.plot(x=\"errorBalanceOrg\",y=\"errorBalanceDest\",color=\"red\",kind=\"scatter\",ax=ax,label=\"Fraudulent transactions\")\n","vplot = valid.plot(x=\"errorBalanceOrg\",y=\"errorBalanceDest\",color=\"green\",kind=\"scatter\",\\\n","                   alpha=0.01,ax=ax,label=\"Valid transactions\")\n","plt.title(\"errorBalanceOrg vs errorBalanceDest\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6846efff6ebcc505416e1effb9c753081788ffb2"},"cell_type":"markdown","source":["It seems that many fraudulent transactions that are found in the top right corner where errorBalanceDest > 0, whereas transactions occur much more often when the errorBalanceDest <= 0. "]},{"metadata":{"trusted":false,"_uuid":"2cee9367385053a1051342782b71002d0df068c7"},"cell_type":"code","source":["print(\"Proportion of fraudulent transactions with errorBalanceDest > 0: \", len(fraud[fraud.errorBalanceDest > 0])/len(fraud))\n","print(\"Proportion of valid transactions with errorBalanceDest > 0: \", len(valid[valid.errorBalanceDest > 0])/len(valid))\n","print(\"Proportion of fraudulent transactions with errorBalanceOrg > 0: \", len(fraud[fraud.errorBalanceOrg > 0])/len(fraud))\n","print(\"Proportion of valid transactions with errorBalanceOrg > 0: \", len(valid[valid.errorBalanceOrg > 0])/len(valid))\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe077ca819d8d927dee1c145820dfa4a03ab766b"},"cell_type":"markdown","source":["### Conclusion: \n","\n","The spread of errors in both the balanceOrg and balanceDest variables are large, however valid transactions are much more likely to have an errorBalanceOrg > 0.\n","\n","Similarly, fraudulent transactions are much more likely to have errorBalanceDest > 0 than valid transactions.\n","\n","In addition, only valid transactions have errorBalanceDest > 10,000,000\n","\n","These distinctions and probably more, make errorBalanceDest and errorBalanceOrg potentially effective features. "]},{"metadata":{"_uuid":"3e55d75529888b174f0603fe96da62bdb50616a5"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"8b1419b7c9b32585b4c7c0ebf26f0937bba59264"},"cell_type":"markdown","source":["### 1.6 Another Look at Transaction Types and Account Names\n","<a id='AcctandTrans'></a>"]},{"metadata":{"_uuid":"deec337aca21953afaddf2b4e4ee5ff27d0d8348"},"cell_type":"markdown","source":["According to the overview of the dataset on kaggle:\n","\n","\n","*This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.*\n","\n","Let's see if this is reflected in the fraud dataset"]},{"metadata":{"trusted":false,"_uuid":"cc09a8621245efe3202d401e6e2e97913706f9d9"},"cell_type":"code","source":["print(\"Fraud transactions by type: \\n\",fraud.type.value_counts())"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c70b925251374537d45a3696afc9a511bef6fee"},"cell_type":"markdown","source":["Clearly, fraudulent transactions exclusively involved cashouts and transfers"]},{"metadata":{"trusted":false,"_uuid":"9ab1c91c8ed6c0cd7b1d6c38de362002aae5887d"},"cell_type":"code","source":["pd.DataFrame.head(data_new,13)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a31a17b27e1d232e0a4cb35079c557b1a6f7f118"},"cell_type":"markdown","source":["However, in this sample the account that the money to transferred to tends to not be the account used to make the cashout. \n","\n","\n","Let's test this statement programmatically."]},{"metadata":{"trusted":false,"_uuid":"90754ed1b066d6b045703107e0ad68e9d3925c7e"},"cell_type":"code","source":["# separating transfers and cashouts for fraud accounts\n","\n","fraud_transfer = fraud[fraud[\"type\"] == \"TRANSFER\"]\n","fraud_cashout = fraud[fraud[\"type\"] == \"CASH_OUT\"]\n","\n","# checking if the recipient account of a fraudulent transfer was used as a sending account for cashing out \n","fraud_transfer.nameDest.isin(fraud_cashout.nameOrig).any()\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7661c37d931634c4cbbb88207cfaeb75562e0719"},"cell_type":"markdown","source":["### Conclusion:\n","\n","Thus in this dataset, for fraudulent transactions, the account that received funds during a transfer was not used at all for cashing out.\n","\n","If that is the case, there seems to be no use for nameOrig or nameDest since there seems to be no restrictions on which accounts cashout from fraudulent transactions.\n","\n","Thus, I am omitting the nameOrig and nameDest columns from analysis."]},{"metadata":{"trusted":false,"_uuid":"2ba42cadcc6cdacfb9dc1381b3e0a6c303cf6e77"},"cell_type":"code","source":["# getting rid of nameOrig and nameDest column.\n","names = [\"nameOrig\",\"nameDest\"]\n","fraud = fraud.drop(names, 1)\n","valid = valid.drop(names,1)\n","data_new = data_new.drop(names,1)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b1940b825225deca217f91a8213978b28fbcd5b"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"317485c6424fcd06968f32a1d3c2ed6792f432a4"},"cell_type":"markdown","source":["### 1.7 Looking at Flagged Transactions\n","<a id='Flag'></a>"]},{"metadata":{"_uuid":"23c98e4ca55081610acb3696c6d9258e3347b041"},"cell_type":"markdown","source":["From the overview, the variable isFlaggedFraud is described as transactions that were flagged as fraud.\n","\n","To be flagged as fraud, the transaction would have to be fraudulent and involve a transfer of more than 200, 000 units in a specified currency.\n","\n","With that in mind, I have some questions. "]},{"metadata":{"trusted":false,"_uuid":"c651cfe9a2b6eeeaa6d5e1b2c25f886218b02dd0"},"cell_type":"code","source":["# how many observations were flagged as Fraud?\n","flagged = data_new[data_new[\"isFlaggedFraud\"] == 1]\n","flagged_correctly = sum(flagged[\"isFraud\"] == 1)\n","flagged_wrongly = len(flagged) - flagged_correctly\n","total = flagged_correctly + flagged_wrongly\n","print(flagged_correctly,\" observations were flagged correctly and \", flagged_wrongly, \\\n","      \" observations were flagged wrongly for a total of \", total, \" flagged observations.\")\n","\n","# how many observations where the transaction is fraudulent, the transaction is a transfer and the amount is greater \n","# than 200, 000 are in the dataset\n","should_be_flagged = fraud[(fraud[\"amount\"] > 200000) & (fraud[\"type\"] == \"TRANSFER\")]\n","print(\"number of observations that should be flagged: \",len(should_be_flagged))"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fcad7a9e8fc5422cdda49c755c3e9af86644e15e"},"cell_type":"markdown","source":["### Conclusion: \n","\n","In a modified dataset with more than 2 million observations, a variable that brings attention to only 16 observations is insignificant.\n","\n","Furthermore, the number of transactions that should have been flagged far exceeds the number of observations that were actually flagged.\n","\n","In addition, I am trying to develop a new fraud detection screen that does not depend on a pre-existing fraud detection scheme.\n","\n","For that reason, I am omitting the isFlaggedFraud column from the analysis."]},{"metadata":{"trusted":false,"_uuid":"9d5941c2138c57991ceae60a9e63bdfc8540d587"},"cell_type":"code","source":["# dropping isFlaggedFraud column from the fraud,valid, and new_data datasets\n","\n","fraud = fraud.drop(\"isFlaggedFraud\",1)\n","valid = valid.drop(\"isFlaggedFraud\",1)\n","data_new = data_new.drop(\"isFlaggedFraud\",1)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d7bd8e27dedcfbbf3f6b171d55fa68357d24a263"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"09956f29079ba73497968d29391ef126876f6841"},"cell_type":"markdown","source":["### 1.8 Looking at Time\n","<a id='Time'></a>"]},{"metadata":{"trusted":false,"_uuid":"29cf4d5f3d71318aa5abf8ea4c26566f4e95fd0e"},"cell_type":"code","source":["# Time patterns\n","\n","bins = 50\n","\n","valid.hist(column=\"step\",color=\"green\",bins=bins)\n","plt.xlabel(\"1 hour time step\")\n","plt.ylabel(\"# of transactions\")\n","plt.title(\"# of valid transactions over time\")\n","\n","fraud.hist(column =\"step\",color=\"red\",bins=bins)\n","plt.xlabel(\"1 hour time step\")\n","plt.ylabel(\"# of transactions\")\n","plt.title(\"# of fraud transactions over time\")\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1f737cccac3fb58e3c5c2166d550ae9087f2d676"},"cell_type":"markdown","source":["There are stark difference between the *step* data between valid and fraud transactions.\n","\n","1. A large proportion of valid transactions occur between around the 0th and 60th timestep as well as the 110th and 410th time-steps.\n","2. The frequency at which fraudulent transactions occur does not seem to change much over time.\n","\n","However the visualizations showcase the number of transactions for each time step over the course of a month.\n","\n","Let's see what the patterns look like over any particular, day of the week or hour of the day.\n"]},{"metadata":{"trusted":false,"_uuid":"f50fe30c6b175e105cbe29e0f1c7cc6af27dfa69"},"cell_type":"code","source":["# getting hours and days of the week\n","num_days = 7\n","num_hours = 24\n","fraud_days = fraud.step % num_days\n","fraud_hours = fraud.step % num_hours\n","valid_days = valid.step % num_days\n","valid_hours = valid.step % num_hours\n","\n","# plotting scatterplot of the days of the week, identifying the fraudulent transactions (red) from the valid transactions (green) \n","plt.subplot(1, 2, 1)\n","fraud_days.hist(bins=num_days,color=\"red\")\n","plt.title('Fraud transactions by Day')\n","plt.xlabel('Day of the Week')\n","plt.ylabel(\"# of transactions\")\n","\n","plt.subplot(1,2,2)\n","valid_days.hist(bins=num_days,color=\"green\")\n","plt.title('Valid transactions by Day')\n","plt.xlabel('Day of the Week')\n","plt.ylabel(\"# of transactions\")\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c11c046ad2e9abb6632c2b24009a3d16e7090418"},"cell_type":"markdown","source":["Note: With respect to days, day 0 does not necessarily mean the first day of the week, Sunday. \n","\n","E.g If day 0 is Wednesday, then day 1 is Thursday, day 2 is Friday and so on...\n","\n","From the graphs above, there is little evidence to suggest that fraudulent transactions occur at particular days of the week.\n","\n","Much like valid transactions, fraudulent transactions seem to occur uniformally for each day of the week.\n","\n","Thus I won't make a feature showing what day of the week that the transaction occured."]},{"metadata":{"trusted":false,"_uuid":"c7b9dbde7beb484cb41f9a1199b29500d425a0ac"},"cell_type":"code","source":["plt.subplot(1, 2, 1)\n","fraud_hours.hist(bins=num_hours, color=\"red\")\n","plt.title('Fraud transactions by Hour')\n","plt.xlabel('Hour of the Day')\n","plt.ylabel(\"# of transactions\")\n","\n","\n","plt.subplot(1, 2, 2)\n","valid_hours.hist(bins=num_hours, color=\"green\")\n","plt.title('Valid transactions by Hour')\n","plt.xlabel('Hour of the Day')\n","plt.ylabel(\"# of transactions\")\n","\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45430dbcc74b5994978fbac0cc866f505a6086d6"},"cell_type":"markdown","source":["### Conclusion:\n","\n","Note: With respect to days, hour 0 does not necessarily mean 1am in the morning. \n","\n","E.g If hour 0 is 9am, then hour 1 is 10 am, hour 2 is 11am and so on...\n","\n","From the graphs above, there is strong evidence to suggest that from hour 0 to hour 9 (inclusive) valid transactions very seldom occur. On the other hand, fraudulent transactions still occur at similar rates to any hour of the day outside of hours 0 to 9 (inclusive).\n","\n","In response to this, I will create another feature HourOfDay, which is the step column with each number taken to modulo 24."]},{"metadata":{"trusted":false,"_uuid":"455b8e8ab3b1ead3de4b8d01ca0e52cb49d56d1e"},"cell_type":"code","source":["dataset1 = data_new.copy()\n","\n","\n","# adding feature HourOfDay to Dataset1 \n","dataset1[\"HourOfDay\"] = np.nan # initializing feature column\n","dataset1.HourOfDay = data_new.step % 24\n","\n","\n","print(\"Head of dataset1: \\n\", pd.DataFrame.head(dataset1))\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce494e001c7c1d78ca8feea1544ddc27771879c0"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"061fbd106c2033815f4fd26804d0095e4168b8cb"},"cell_type":"markdown","source":["### 1.9 Looking at Amounts Moved in Transactions\n","<a id='Amt'></a>"]},{"metadata":{"trusted":false,"_uuid":"68cd168a839046714b8429831eb6ce3e27cd7343"},"cell_type":"code","source":["# Seeing summary statistics of the data\n","\n","print(\"Summary statistics on the amounts moved in fraudulent transactions: \\n\",pd.DataFrame.describe(fraud.amount),\"\\n\")\n","print(\"Summary statistics on the amounts moved in valid transactions: \\n\", pd.DataFrame.describe(valid.amount),\"\\n\")\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e56ad2b677c9961e1b63c945e4031e9d6f05d024"},"cell_type":"markdown","source":["It seems that during fraudulent transactions, the amount moved is capped at 10 million currency units.\n","\n","Whereas for valid transactions, the amount moved is capped at about 92.4 million currency units.\n","\n","when plotting time-steps against amount moved we get this plot...\n"]},{"metadata":{"trusted":false,"_uuid":"8a27b5f0a6849e6342254f843c843c85c5cb09cf"},"cell_type":"code","source":["# plotting overlayed step vs amount scatter plots\n","\n","alpha = 0.3\n","fig,ax = plt.subplots()\n","valid.plot.scatter(x=\"step\",y=\"amount\",color=\"green\",alpha=alpha,ax=ax,label=\"Valid Transactions\")\n","fraud.plot.scatter(x=\"step\",y=\"amount\",color=\"red\",alpha=alpha,ax=ax, label=\"Fraudulent Transactions\")\n","\n","plt.title(\"1 hour timestep vs amount\")\n","plt.xlabel(\"1 hour time-step\")\n","plt.ylabel(\"amount moved in transaction\")\n","plt.legend(loc=\"upper right\")\n","\n","# plotting a horizontal line to show where valid transactions behave very differently from fraud transactions\n","\n","plt.axhline(y=10000000)\n","plt.show()\n","\n","\n","print(\"Proportion of transactions where the amount moved is greater than 10 million: \", \\\n","      len(data_new[data_new.amount > 10000000])/len(data_new))\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52211c3fc4eea57255744989f6ce4faa3ec42f3b"},"cell_type":"markdown","source":["### Conclusion:\n","\n","Only valid transaction involved amounts larger than 10,000,000, however these transactions make up less than 0.01% of the relevant data.\n","\n","When the amounts moved is less than 10,000,000 there doesn't seem to be a large difference fraudulent and valid transactions.\n","\n","I leave the variable amount as is without creating a feature out of it."]},{"metadata":{"trusted":false,"_uuid":"08bc603d201171aeaaa1c1c9fd9a19cd7330093f"},"cell_type":"code","source":["# finalizing dataset\n","dataset = dataset1.copy() # unchanged dataset1"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15a9d64e90ef006bfc712dec01366f0d38dc1715"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"13ed100736440c745b4174188c577fab4aad9bc4"},"cell_type":"markdown","source":["## 2. Pre-processing Data\n","<a id='Preprocess'></a>"]},{"metadata":{"_uuid":"0dee8617423d3aec4f4a3e869664e0def136ff08"},"cell_type":"markdown","source":["### 2.1 Handling Categorical Variables\n","<a id='Cat'></a>\n","\n","Note that many algorithms require that all elements used in the computation are numbers.\n","\n","For that reason, the categorical variables encoded as string must be encoded as numbers. Since there is no \"order\"/\"hierarchy\" in the type variable, the method I will use to numerically encode categorical variables is called 1 hot encoding.\n","\n","One-Hot encoding involves creating indicator variables for each category in a categorical variable.\n","\n","If an observation is part of a particular category (e.g. the transaction type is CASH_OUT), the indicator variable associated with the category would be 1. If it isn't part of a particular category, then the indicator variable associated with that category would be 0.\n"]},{"metadata":{"trusted":false,"_uuid":"92f5bfb1f6dd1d8291b1112d2df097413cd03378"},"cell_type":"code","source":["# getting one-hot encoding of the 'type' variable\n","\n","dataset = pd.get_dummies(dataset,prefix=['type'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"82a78ef5ec83d05597051dd4a551dec91f93cd28"},"cell_type":"code","source":["pd.DataFrame.head(dataset)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcf78dd0b164fef2e492248dbedff35f4d28845b"},"cell_type":"markdown","source":["## 2.2 Splitting and Standardizing Data.\n","<a id='Split'></a>\n","Similarly, many, if not all, machine learning algorithms perform better when the data is standardized/normalized (when all values are between 0 and 1 inclusive).\n","\n","We will do this to standardize the data without standardizing the target variable isFraud.\n","\n","Additionally, we will also split the data up into training sets and testing sets. A common split is to separate 80% of the data as the training set and the rest as the testing set. However we will rely on the \"default\" split which is 75% of the data is used as the training set, 25% is used as the testing set.\n"]},{"metadata":{"trusted":false,"_uuid":"0018683e4c757a67a7b3fde1be8d9a533e992233"},"cell_type":"code","source":["# Setting random_state and seed so that the training/testing splits and model results are reproducible\n","RandomState = 42\n","seed(21)\n","\n","\n","# 42 is used often due to Hitchhiker's Guide to the Galaxy, I will use a number that a far smaller group may understand.\n","# Not that the actual number doesn't matter and is only used to make sure results are reproducible.\n","# creating training and testing sets\n","X = dataset.drop(\"isFraud\",1)\n","y = dataset.isFraud\n","X_train, X_test, y_train, y_test = train_test_split(X, y)\n","    \n","# Normalizing data so that all variables follow the same scale (0 to 1)\n","scaler = StandardScaler()\n","\n","# Fit only to the training data\n","scaler.fit(X_train)\n","\n","# Now apply the transformations to the data:\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f0902552e5c64425d0c869634d5aed5ba7651c33"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"9cb20c705c396b934f165e81b0a732ad34bb50fb"},"cell_type":"markdown","source":["## 3 Model Selection\n","<a id='Models'></a>"]},{"metadata":{"_uuid":"735f12cde3cb63edca0551798313b9e174495b16"},"cell_type":"markdown","source":["### 3.1 Model 1: Artificial Neural Networks\n","<a id='Model-1'></a>\n","Since correctly predicting fraudulent and valid transactions is the main goal and my dataset is fairly large (> 2 million rows), I think that Neural Networks would be a good choice. \n","\n","In particular, I will be using a Multilayered Perceptron.\n","\n","Multi Layer perceptron (MLP) is a feedforward neural network with at least 1 layer between the input and output layer. Data is trained from the input layer up until the output layer ([Techopedia](https://www.techopedia.com/definition/20879/multilayer-perceptron-mlp])).\n","\n"]},{"metadata":{"trusted":false,"_uuid":"4b215f4401d04dfdc8d719ccf7168caa849b5264"},"cell_type":"code","source":["ncols = len(X.columns)\n","hidden_layers = (ncols,ncols,ncols)\n","max_iter = 1000\n","MLP = MLPClassifier(hidden_layer_sizes=hidden_layers,max_iter=1000,random_state=RandomState)\n","\n","# training model\n","MLP.fit(X_train,y_train)\n","    \n","# evaluating model on how it performs on balanced datasets\n","predictionsMLP = MLP.predict(X_test)\n","CM_MLP = confusion_matrix(y_test,predictionsMLP)\n","CR_MLP = classification_report(y_test,predictionsMLP)\n","fprMLP, recallMLP, thresholdsMLP = roc_curve(y_test, predictionsMLP)\n","AUC_MLP = auc(fprMLP, recallMLP)\n","    \n","resultsMLP = {\"Confusion Matrix\":CM_MLP,\"Classification Report\":CR_MLP,\"Area Under Curve\":AUC_MLP}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"bdf5ea8b0b941bb72519a7ccd306172fafef2ff3"},"cell_type":"code","source":["# showing results from Multilayered perceptrons developed from each dataset\n","for measure in resultsMLP:\n","    print(measure,\": \\n\",resultsMLP[measure])"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"288e2335a1403d12178a9677c01fd2907e7c7b5b"},"cell_type":"markdown","source":["In the context of fraud detection the performance of the Neural Network isn't terrible, but it isn't great either. The loss is performance is very likely due to the phenomenon that Neural Networks perform worse when the data is imbalanced. When data is imbalanced, Neural Networks and many other models trained on the data tend to be very biased towards the *majority class*. In our case, the majority class are valid transactions.  \n","\n","This model will be the benchmark that I will compare other individual models against.\n","\n","The next few models will be generated from methods that are well-known for handling imbalanced data effectively."]},{"metadata":{"_uuid":"acdaf9722037b647f940b2d7044971c4c01c3e1e"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"83a943645260f03b38334868a505c86bd4ba60b3"},"cell_type":"markdown","source":["### 3.2 Model 2: Random Forest.\n","<a id='Model-2'></a>\n","\n","A random forest is an algorithm that generates several decisions trees and pools the results of each tree to make a more robust prediction ([Eulogio, 2017](https://www.datascience.com/resources/notebooks/random-forest-intro)). \n","\n","Another great thing about Random Forest is that I can assign weights to each class to reduced the bias of the model towards the majority class, in this case valid transaction."]},{"metadata":{"trusted":false,"_uuid":"678d5e9f3078534be720e2d2b19d50815bfafe5b"},"cell_type":"code","source":["# Train model\n","parametersRF = {'n_estimators':15,'oob_score':True,'class_weight': \"balanced\",'n_jobs':-1,\\\n","                 'random_state':RandomState}\n","RF = RandomForestClassifier(**parametersRF)\n","fitted_vals = RF.fit(X_train, y_train)\n"," \n","# Predict on testing set\n","predictionsRF = RF.predict(X_test)\n"," \n","     \n","# Evaluating model\n","CM_RF = confusion_matrix(y_test,predictionsRF)\n","CR_RF = classification_report(y_test,predictionsRF)\n","fprRF, recallRF, thresholdsRF = roc_curve(y_test, predictionsRF)\n","AUC_RF = auc(fprRF, recallRF)\n","\n","resultsRF = {\"Confusion Matrix\":CM_RF,\"Classification Report\":CR_RF,\"Area Under Curve\":AUC_RF}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"598653e9bd99248e6cc2cc068443fdc62b234ee9"},"cell_type":"code","source":["# showing results from Random Forest\n","\n","for measure in resultsRF:\n","    print(measure,\": \\n\",resultsRF[measure])"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d5cc27f6d798851e5505597deb28afb4275ffdc"},"cell_type":"markdown","source":["As expected, the Random Forest performs much better than the Neural Networks. Instead of crowning this model as the best model, let's try another model known for performing well in imbalanced datasets."]},{"metadata":{"_uuid":"b6cc2474da2995d440820cd432c95645248973f7"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"ab838125e069d1dc87be0551f33baee37c8a788b"},"cell_type":"markdown","source":["### 3.3 Model 3: e**X**treme **G**radient **B**oosting Trees (or XGB trees for short)\n","<a id='Model-3'></a>\n","\n","This algorithm is well known for being used in imbalanced datasets. Similar to Random Forests, the algorithm generates several decision trees and pooling the results. \n","\n","However,instead of generating multiple full blown decision trees in parallel and pooling the results, it generates multiple trees formed by weak learners sequentially and then it pools the results ([Ravanshad, 2018](https://medium.com/@aravanshad/gradient-boosting-versus-random-forest-cfa3fa8f0d80)).\n","\n","As with Random Forests, I could set weights such that the model is less biased towards the majority class."]},{"metadata":{"trusted":false,"_uuid":"69142693de84287f4d633a3c57ab6ad730eea378"},"cell_type":"code","source":["# Train model\n","weights = (y == 0).sum() / (1.0 * (y == 1).sum()) # for unbalanced datasets, these weights are recommended\n","parametersXGB = {'max_depth':3,'scale_pos_weight': weights,'n_jobs':-1,\\\n","                 'random_state':RandomState,'learning_rate':0.1}\n","XGB = XGBClassifier(**parametersXGB)\n","    \n","fitted_vals = XGB.fit(X_train, y_train)\n"," \n","# Predict on testing set\n","predictionsXGB = XGB.predict(X_test)\n"," \n","     \n","# Evaluating model\n","CM_XGB = confusion_matrix(y_test,predictionsXGB)\n","CR_XGB = classification_report(y_test,predictionsXGB)\n","fprXGB, recallXGB, thresholds_XGB = roc_curve(y_test, predictionsXGB)\n","AUC_XGB = auc(fprXGB, recallXGB)\n","resultsXGB = {\"Confusion Matrix\":CM_XGB,\"Classification Report\":CR_XGB,\"Area Under Curve\":AUC_XGB}"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5e260b5509a1af6ad4e3f07e503ab84d8198c4d9"},"cell_type":"code","source":["# showing results from Extreme Gradient Boosting\n","for measure in resultsXGB:\n","    print(measure,\": \\n\",resultsXGB[measure],\"\\n\")"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7bcd4b063eee3015b2736bd751e31bae07c1e3c3"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"9df90a5687f73937dd0a13438a7730ff8ce74938"},"cell_type":"markdown","source":["### 3.4 Comparing Performances\n","<a id='Visuals'></a>"]},{"metadata":{"_uuid":"26aba1cf9b0bf36071bebb5fad64a828d7138848"},"cell_type":"markdown","source":["Clearly, the random forest and the extreme gradient boosted trees performed better than the neural networks, but which one is better?\n","\n"," Instead of comparing all of the metrics from a purely statistical or mathematical point of view, let's look at them at give some practical interpretation.\n","\n","First off, let's compare their confusion matrices.\n","\n","Additionally, instead of comparing the number of correct predictions, let us compare the number of wrong predictions."]},{"metadata":{"trusted":false,"_uuid":"57b0232c8e23176ddc318c71a0b10606bc7831a3"},"cell_type":"code","source":["print(\"Number of valid transactions labelled as fraudulent by Random Forest: \\n\", CM_RF[0,1])\n","print(\"Number of valid transactions labelled as fraudulent by XGB trees: \\n\", CM_XGB[0,1])\n"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7ddc6ba5634ec2e894bb8cda1680117e5b7a51a"},"cell_type":"markdown","source":["On the basis on limiting the amount of valid transaction labelled as fraudulent, the Random Forest performed better."]},{"metadata":{"trusted":false,"_uuid":"6c7bb568a4a8f736fcbd1e19af4da38cc9c75467"},"cell_type":"code","source":["print(\"Number of fraud transactions labelled as valid by Random Forest: \\n\", CM_RF[1,0])\n","print(\"Number of fraud transactions labelled as valid by XGB trees: \\n\", CM_XGB[1,0])"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3977616fdb4b5227c67ed70fa62f2920cec70355"},"cell_type":"markdown","source":["On the basis on limiting the amount of fraudulent transactions labelled as fraudulent, the XGB trees performed better."]},{"metadata":{"_uuid":"e31feceb286ecdabf0d8a82acc0d54ed2feeb7bf"},"cell_type":"markdown","source":["Based purely on the results on the confusion matrix, the better model is decided by which model incurs the lowest costs.\n","\n","If the combined cost of mislabelling over 100 more valid transactions as fraudulent exceeds the cost of mislabelling a few more fraudulent transactions as valid then the random forest would be a better model.\n","\n","Otherwise, the Extreme Gradient Boosted model would be superior.\n","\n","Some of the other metrics tracked (precision, recall, f1-score which are found in the classification report) will convey the same information that is offered by the confusion matrix.\n","\n","So what if we compared the classification reports?"]},{"metadata":{"trusted":false,"_uuid":"2aa5653b92bdd3b36bbd908cf456471c9563323e"},"cell_type":"code","source":["print(\"Note: scores in the same vertical level as 0 are scores for valid transactions. \\n \\\n","      Scores in the same vertical level as 1 are scores for fraudulent transactions. \\n\")\n","print(\"Classification Report of Random Forest: \\n\", CR_RF)\n","print(\"Classification Report of XGB trees: \\n\", CR_XGB)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"842d31876ff45673688e26ee4c0222096f4f786a"},"cell_type":"markdown","source":["While the recall scores for both models are identical, the Random Forest performed slightly better in terms of their precision score for fraudulent transactions. \n","\n","This means that there are considerably less false positives (identifying valid transactions as fraudulent) in the Random Forest than in the XGB model. This makes sense given what we've seen in their confusion matrices (a few valid transactions labelled as fraudulent by Random Forest, compared to over 100 by the XGB model). \n","\n","Based on the classification report, the Random Forest is superior."]},{"metadata":{"_uuid":"3ab0138ddff8134e6dac56397a19b0b881a772c3"},"cell_type":"markdown","source":["What about AUC's (area under the curve)?\n","\n","The only reason why I computed AUC's is because it is a popularly used metric to measure performance in kaggle competitions. \n","The curve in Area Under **Curve** is a plot of the true positive rates (in our case, the proportion of valid transactions labelled as valid) against the false positive rate (in our case, the proportion of fraudulent transactions labelled as valid). The curve is also known as the Receiver Operating Characteristic Curve or ROC.\n","\n","The ideal AUC is then 1 (all transactions predicted as valid are actually valid). \n","\n"]},{"metadata":{"trusted":false,"_uuid":"0ff09fd1d1bad6c01b3d8af81b619080abe21baa"},"cell_type":"code","source":["print(\"\\nReceiver Operating Characteristic Curves for Random Forests and Extreme Gradient Boosted Trees: \\n\")\n","plt.subplot(1, 2, 1)\n","plt.plot(fprRF, recallRF, color='purple', label='ROC curve (area = %0.2f)' % AUC_RF)\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","plt.xlim([-0.01, 1.0])\n","plt.ylim([-0.01, 1.0])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC (Random Forest)')\n","plt.legend(loc=\"lower right\")\n","\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(fprRF, recallRF, color='green', label='ROC curve (area = %0.2f)' % AUC_RF)\n","plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n","plt.xlim([-0.01, 1.0])\n","plt.ylim([-0.01, 1.0])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC (XGB)')\n","plt.legend(loc=\"lower right\")\n","\n","plt.tight_layout()\n","plt.show()\n","\n","print(\"\\nAUC of Random Forest: \\n\", AUC_RF)\n","print(\"\\nAUC of XGB trees: \\n\", AUC_XGB)"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03338f897cea53d1139d9112bbcb9710976d4cab"},"cell_type":"markdown","source":["While the AUC of the Extreme Gradient Boosted Trees is slightly greater than the AUC of the Random Forests. For all practical purposes, they are essentially the same."]},{"metadata":{"_uuid":"7e136452483763a171201bf7040efacde9bfca9f"},"cell_type":"markdown","source":["Overall, I would deem the Random Forest as the superior choice because I think the cost of resolving over a 100 valid transactions labelled as fraudulent would exceed the cost of resolving a handful more fraudulent transactions that have been passed off as valid.\n","\n","With that said, this may not true in actual companies. The best decision would be to consult people with experience dealing with mislabelled transactions."]},{"metadata":{"_uuid":"7c4d3c39a7310a9f72c5ae1d29c09d58f009f42b"},"cell_type":"markdown","source":["Black-box/Non-parametric methods (like Neural Networks, Random Forests, Extreme Gradient Boosted Trees) are known to not be interpretable (due to having a lack of an equation to interpret from).\n","\n","Nonetheless, let's take a look at what features ended up being the most important in classifying transactions."]},{"metadata":{"trusted":false,"_uuid":"6720ac28c7ad37476acc7fefd046ece99a6ce398"},"cell_type":"code","source":["x = np.arange(ncols)\n","\n","# getting importances of features\n","importances = RF.feature_importances_\n","\n","# getting the indices of the most important feature to least important\n","sort_ind = np.argsort(importances)[::-1]\n","plt.figure(figsize=(18,7))\n","plt.bar(x, importances[sort_ind])\n","plt.xticks(x,tuple(X.columns.values[sort_ind]))\n","plt.title(\"Important Features: Greatest to Least\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"60154850c3e0762f37b81bb9aae0e6c5d8ef43b8"},"cell_type":"markdown","source":["It seems that errorBalanceOrg ended by the most important feature by far for classifying transactions followed by oldBalanceOrg and newBalanceOrig.  "]},{"metadata":{"_uuid":"0cf60817daf32e021bbcfe9c7b4426e10593210d"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]},{"metadata":{"_uuid":"e3f74eaa968a3ce2cd29fe37bc1ca1074c09ccaa"},"cell_type":"markdown","source":["## 4 Final Remarks\n","<a id='Final'></a>"]},{"metadata":{"_uuid":"383d6e2d36b0e04cddb19419b2b1c1f8c09ad432"},"cell_type":"markdown","source":["From the exploring the dataset, we uncovered patterns that allowed us to construct important features and discard useless ones. \n","\n","We applied a few popular machine learning algorithms and saw that methods that involved generating multiple decisions trees and pooling their results together performed better than Multi-Layered Perceptrons (a type of Neural Network). While it may seem that Neural Networks are unsuitable for unbalanced datasets, in some occasions, techniques such as SMOTE, oversampling and undersampling can resolve such issues.  \n","\n","Finally, between the Random Forests and the Extreme Gradient Boosting, practical considerations were used to decide that the Random Forests were a better model.\n","\n","In particular, Random Forests were better because we thought that the cost of dealing with over a 100 wrongly labeled valid transactions is more expensive than the cost of dealing with a few additional fraudulent transactions.\n","\n","Working with this dataset was a lot of work and a lot of fun. I learned a lot about exploring data and when to apply/not apply certain methods.\n","\n","Thanks for reading! . "]},{"metadata":{"_uuid":"a496482363cb386a06545f8b7fb91f173ef954d4"},"cell_type":"markdown","source":["<a href='#top'>go back to top</a>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7-final"}},"nbformat":4,"nbformat_minor":1}